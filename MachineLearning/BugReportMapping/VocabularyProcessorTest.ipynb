{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /Users/Tian/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sqlalchemy import create_engine\n",
    "import re\n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "import tensorflow as tf\n",
    "from tensorflow.contrib import learn\n",
    "from TextCNN import TextCNN\n",
    "\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import os\n",
    "import time\n",
    "import datetime\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def sentence_to_stemmed(sentence):\n",
    "    sentence = sentence.lower()\n",
    "    sentence = sentence.split()\n",
    "    porterStemmer = PorterStemmer()\n",
    "    sentence = [porterStemmer.stem(word) for word in sentence if not word in set(stopwords.words('english'))]\n",
    "    sentence = ' '.join(sentence)\n",
    "\n",
    "    return sentence\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_ui = pd.read_csv('eclipse_platform_ui_no_space.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "corpus = []\n",
    "labels = []\n",
    "\n",
    "rows, cols = df_ui.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "End reading\n"
     ]
    }
   ],
   "source": [
    "for i in range(rows):\n",
    "    report = re.sub('[^a-zA-Z0-9]', ' ', (df_ui['summary'][i]))\n",
    "    label = df_ui['files'][i]\n",
    "    corpus.append(sentence_to_stemmed(report))\n",
    "    label = re.sub('\\.', '_', label)\n",
    "    label = re.sub('/', '__', label)\n",
    "    labels.append(label)\n",
    "    #if i % 100 == 0:\n",
    "        #print('%d lines processed.\\n' % i)\n",
    "print('End reading')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['bug 384108 junit view icon longer show progress execut test', 'bug 385394 perform issu regard enabl state handl menucontribut contain command toolitemupdatetim put constant load cpu']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "6495"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(corpus[0:2])\n",
    "len(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "24"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_document_length = max([len(x.split(\" \")) for x in corpus])\n",
    "max_document_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1  2  3  4  5  6  7  8  9 10  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 1 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25  0  0  0  0  0  0  0  0]]\n"
     ]
    }
   ],
   "source": [
    "## Create the vocabularyprocessor object, setting the max lengh of the documents.\n",
    "vocab_processor = learn.preprocessing.VocabularyProcessor(max_document_length)\n",
    "\n",
    "## Transform the documents using the vocabulary.\n",
    "x = np.array(list(vocab_processor.fit_transform(corpus)))  \n",
    "print(x[0:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
